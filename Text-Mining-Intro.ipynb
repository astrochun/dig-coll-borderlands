{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to text mining\n",
    "\n",
    "After this lesson, students will be able to:\n",
    "\n",
    "1. Explain the difference between a code block and a text block in Jupyter Notebooks\n",
    "2. Write a short command in Python and execute the command\n",
    "3. Execute pre-written Python code to create a word frequency through time plot\n",
    "4. Explain what a file path is\n",
    "5. Describe how to choose words for searching\n",
    "6. Update Python code to perform word frequency calculations on different newspaper title\n",
    "7. Create a plot showing word frequency over time on a chosen newspaper and time frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Explain the difference between a code block and a markdown block in Jupyter Notebooks\n",
    "Jupyter notebooks allow us to mix in computer programming code with readable text. Each notebook is broken into several \"blocks\", or sections. A block can _either_ have code (a code block) or text (a markdown block). The text you are reading right now is in a markdown block, but we will start by looking at code blocks. We can tell the difference because code blocks are shown with gray shading. We can _run_, or execute a block by clicking the gray box and pressing the &#x25B6; Run button at the top of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Welcome to Python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work more with code blocks in a bit, but what about markdown blocks? Markdown blocks are where we can write text and use some simple styling. You can change the text of the markdown block by clicking on the block, pressing \"Enter\" and then editing the content. Try this out on this text block; when you finished adding the text, press the Run button again to have the text formatted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not be doing too much work with markdown blocks, but they can be very useful if you want to write a report and include the code and results of your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a short command in Python and execute the command\n",
    "Click on the code block below and type in the command `print(My name is Jeff)`, but replace \"Jeff\" with your name. When you finish writing the command, execute the code block by pressing the Run button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a print command to print your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably got a syntax error. Why? Compare your command to the first print command that we ran at the beginning of the lesson. What is different? In the code block below, re-write the command to print your name with the syntax we used at the beginning of the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-write the command to print your name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is meant to demonstrate that when we pass computers text information, like \"My name is Jeff\", we need to wrap the text in quotation marks. Missing quotation marks is a common mistake we encounter when doing text data mining in Python.\n",
    "\n",
    "You also probably noticed the instructions in the code block start with a pound sign (`#`) at the beginning of the line. This is known as the comment character, and is how we can write human-readable notes in a code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute pre-written Python code to create a word frequency through time plot\n",
    "\n",
    "We are going to have more opportunities to play with Python code, but let us pause for a moment to consider what we are going to be doing in terms of text data mining. For this project, we have three newspaper titles published in southern Arizona. Those newspapers were scanned and the text was digitized by the Library of Congress. (More information about the newspapers and the digitization process can be found at [https://chroniclingamerica.loc.gov/](https://chroniclingamerica.loc.gov/)).\n",
    "\n",
    "What _we_ are going to do is look at the frequency of certain words over time. That is, we are interested to see how certain words are used in these papers over time. This allows us to identify trends over time without actually reading four years worth of newspapers.\n",
    "\n",
    "There are many more things you can do with text data mining in Python, but they are beyond the scope of this workshop. If you are interested, Library Carpentry has an introduction to text mining lesson at [http://librarycarpentry.org/lc-tdm/index.html](http://librarycarpentry.org/lc-tdm/index.html).\n",
    "\n",
    "But for now, let us start by looking for the frequency of the word \"influenza\" in the _Bisbee Daily Review_ during the years right before and during the global influenza pandemic.\n",
    "\n",
    "We need to provide the following pieces of information:\n",
    "\n",
    "+ The name of the folder to look in corresponding to the newspaper of interest\n",
    "+ The years to consider, here 1917 and 1918,\n",
    "+ The words to look for, here \"influenza\"\n",
    "+ The language the newspaper is written in, in this case English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store information in variables\n",
    "title = \"bisbee-daily-review\"\n",
    "year_list = ['1917', '1918']\n",
    "my_words = ['influenza']\n",
    "language = \"english\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our work by writing `print` commands on all of these variables. The first code block is done for you; fill in the remaining three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value stored in title variable\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value stored in year_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value stored in my_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value stored in language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to tell Python that there are additional packages to load. What does this mean? We will need to use additional programs, written in Python, to perform our text data mining. No need to change anything in the code block, but you will need to execute the block (press the Run button at the top of the window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load additional packages\n",
    "# for data tables\n",
    "import pandas\n",
    "\n",
    "# for file navigation\n",
    "import os\n",
    "\n",
    "# for pattern matching in filenames\n",
    "import re\n",
    "\n",
    "# for text data mining\n",
    "import nltk\n",
    "\n",
    "# for stopword corpora for a variety of languages\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# for splitting data into individual words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# for automated text cleaning\n",
    "import digcol as dc\n",
    "\n",
    "# download the stopwords for several languages\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# for drawing the plot\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block does all the heavy lifting of reading in the text of each day's newspaper, calculating the relative frequency of the word influenza, and finally drawing a plot of the frequency over time. You do not need to change anything in the code block, but you should run it by clicking on the code block and pressing the Run button (or clicking on it, holding down the Control key, and pressing \"Enter\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# No need to edit anything in this code block\n",
    "################################################################################\n",
    "\n",
    "# Creating the pattern of filenames based on years to match\n",
    "years = \")|(\"\n",
    "years = years.join(year_list)\n",
    "pattern = \"((\" + years + \"))([0-9]{4})*\"\n",
    "date_pattern = re.compile(pattern)\n",
    "\n",
    "# Location of files with text for a day's paper\n",
    "volume_path = \"data/sample/\" + title + \"/volumes/\"\n",
    "my_volumes = os.listdir(volume_path)\n",
    "\n",
    "# Use date pattern from above to restrict to dates of interest\n",
    "my_volumes = list(filter(date_pattern.match, my_volumes))\n",
    "\n",
    "# Sort them for easier bookkeeping\n",
    "my_volumes.sort()\n",
    "\n",
    "# Create a table that will hold the relative frequency for each date\n",
    "dates = []\n",
    "for one_file in my_volumes:\n",
    "    one_date = str(one_file[0:4]) + \"-\" + str(one_file[4:6]) + \"-\" + str(one_file[6:8])\n",
    "    dates.append(one_date)\n",
    "\n",
    "# Add those dates to a data frame\n",
    "results_table = pandas.DataFrame(dates, columns = [\"Date\"])\n",
    "\n",
    "# Set all frequencies to zero\n",
    "results_table[\"Frequency\"] = 0.0\n",
    "\n",
    "# Cycle over all issues and do relative frequency calculations\n",
    "for issue in my_volumes:\n",
    "    issue_text = dc.CleanText(filename = volume_path + issue, language = language)\n",
    "    issue_text = issue_text.clean_list\n",
    "    \n",
    "    # Create a table with words\n",
    "    word_table = pandas.Series(issue_text)\n",
    "\n",
    "    # Calculate relative frequencies of all words in the issue\n",
    "    word_freqs = word_table.value_counts(normalize = True)\n",
    "    \n",
    "    # Pull out only values that match words of interest\n",
    "    my_freqs = word_freqs.filter(my_words)\n",
    "    \n",
    "    # Get the total frequency for words of interest\n",
    "    total_my_freq = my_freqs.sum()\n",
    "    \n",
    "    # Format the date from the name of the file so we know where to put\n",
    "    # the data in our table\n",
    "    issue_date = str(issue[0:4]) + \"-\" + str(issue[4:6]) + \"-\" + str(issue[6:8])\n",
    "    \n",
    "    # Add the date & relative frequency to our data table\n",
    "    results_table.loc[results_table[\"Date\"] == issue_date, \"Frequency\"] = total_my_freq\n",
    "    \n",
    "# Analyses are all done, plot the figure\n",
    "my_figure = px.line(results_table, x = \"Date\", y = \"Frequency\")\n",
    "my_figure.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explain what a file path is\n",
    "\n",
    "Need to have a nice graphic showing file paths?\n",
    "```\n",
    "data  \n",
    "  + sample  \n",
    "      + border-vidette  \n",
    "      + bisbee-daily-review  \n",
    "      + el-tucsonense  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Describe how to choose words for searching\n",
    "\n",
    "Need to have students recognize that it is doing _exact_ matching and what the ramifications are for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A copy of the word frequency code\n",
    "# During the lesson, add the word \"flu\" to the list of words being searched for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Update python code to perform word frequency calculations on different newspaper title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting, but will need to change the newspaper title \n",
    "# For notebook, leave it as a copy of what we did before, but during \n",
    "# the lesson, change:\n",
    "#    + newspaper title to el-tucsonsense\n",
    "#    + language to spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create a plot showing word frequency over time on a chosen newspaper and time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for plotting, with variables for students to change: title, language, years, words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to indicate the close of the lesson"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
